repo_name = "TheBloke/llama-2-70b-Guanaco-QLoRA-GPTQ"
model_name = "llama-2-70b-Guanaco-QLoRA-GPTQ"
model_basename = "gptq_model-4bit-128g.safetensors"
max_new_tokens = 2048
token_repetition_penalty_max = 1.15
temperature = 1.99
top_p = 0.18
top_k = 30
stop_sequences = ["###"]
